from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import SGD
import matplotlib.pyplot as plt

import numpy as np
from sklearn.metrics import classification_report


# class labels
class_names = [
    "airplane", "automobile", "bird", "cat", "deer",
    "dog", "frog", "horse", "ship", "truck"
]

# load the CIFAR-10 dataset
(x_data, y_data), (x_test, y_test) = cifar10.load_data()

# normalize pixel values
x_data = x_data.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# split x_data into training and validation sets
x_train = x_data[:43000]
y_train = y_data[:43000]
x_val = x_data[43000:]
y_val = y_data[43000:]

# One-hot encode labels
y_train_cat = to_categorical(y_train, 10)
y_val_cat = to_categorical(y_val, 10)


model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation="relu", input_shape=(32, 32, 3)),
    Flatten(),
    Dense(10, activation="softmax")
])

# Compile the model
model.compile(optimizer=SGD(learning_rate=0.01), loss="categorical_crossentropy", metrics=["accuracy"])


# Train the model
history = model.fit(x_train, y_train_cat,
                    validation_data=(x_val, y_val_cat),
                    epochs=10,
                    batch_size=32)


# Plot training accuracy and loss history
plt.figure(figsize=(12, 5))

# Accuracy subplot
plt.subplot(1, 2, 1)
plt.plot(history.history["accuracy"], label="Train Acc")
plt.plot(history.history["val_accuracy"], label="Val Acc")
plt.title("Model Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

# Loss subplot
plt.subplot(1, 2, 2)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Val Loss")
plt.title("Model Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.tight_layout()
plt.show()


# Inference on test set
y_test_cat = to_categorical(y_test, 10)
test_loss, test_accuracy = model.evaluate(x_test, y_test_cat)
print(f"\nTest set accuracy: {test_accuracy * 100:.2f}%")

# Predict and calculate per-class accuracy
y_pred = model.predict(x_test)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true_labels = y_test.flatten()

# Print classification report
print("\nClassification Report:")
print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))

# Optional: count images per class in test set
unique, counts = np.unique(y_true_labels, return_counts=True)
print("\nTest set class distribution:")
for cls, count in zip([class_names[i] for i in unique], counts):
    print(f"{cls}: {count} images")



